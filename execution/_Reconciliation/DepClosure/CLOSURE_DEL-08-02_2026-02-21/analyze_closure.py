#!/usr/bin/env python3
"""
analyze_closure.py -- Reproducible dependency closure analysis for DEL-08-02
Generated by AUDIT_DEP_CLOSURE on 2026-02-21

This script reproduces the closure analysis performed during the
CLOSURE_DEL-08-02_2026-02-21 run. It reads the Dependencies.csv from
the deliverable folder and runs all 9 core checks.

Usage:
    python3 analyze_closure.py [--execution-root PATH]

Default execution root: execution/
"""

import csv
import json
import os
import re
import sys
from collections import defaultdict
from pathlib import Path


# --- Configuration ---

DEFAULT_EXECUTION_ROOT = "execution/"
SCOPE_DELIVERABLE = "DEL-08-02"
DELIVERABLE_PATH = (
    "execution/PKG-08_Optional_Integrity_Hardening/"
    "1_Working/DEL-08-02_Dependencies_Schema_Linter/"
)
FILTER_ACTIVE_ONLY = True
NORMALIZE_IDS = True
EDGE_FILTER_CLASS = "EXECUTION"
EDGE_FILTER_TARGET_TYPE = "DELIVERABLE"
HUB_THRESHOLD = 20
MAX_CYCLES = 10000

EXPECTED_COLUMNS_V31 = [
    "RegisterSchemaVersion", "DependencyID", "FromPackageID",
    "FromDeliverableID", "FromDeliverableName", "DependencyClass",
    "AnchorType", "Direction", "DependencyType", "TargetType",
    "TargetPackageID", "TargetDeliverableID", "TargetRefID",
    "TargetName", "TargetLocation", "Statement", "EvidenceFile",
    "SourceRef", "EvidenceQuote", "Explicitness", "RequiredMaturity",
    "ProposedMaturity", "SatisfactionStatus", "Confidence", "Origin",
    "FirstSeen", "LastSeen", "Status", "Notes",
]

# Known valid deliverable IDs in the workspace (32 total)
VALID_DELIVERABLE_IDS = {
    "DEL-01-01", "DEL-01-02",
    "DEL-02-01", "DEL-02-02", "DEL-02-03", "DEL-02-04",
    "DEL-03-01", "DEL-03-02", "DEL-03-03", "DEL-03-04",
    "DEL-03-05", "DEL-03-06",
    "DEL-04-01", "DEL-04-02",
    "DEL-05-01", "DEL-05-02", "DEL-05-03", "DEL-05-04",
    "DEL-06-01", "DEL-06-02", "DEL-06-03", "DEL-06-04", "DEL-06-05",
    "DEL-07-01", "DEL-07-02",
    "DEL-08-01", "DEL-08-02", "DEL-08-03", "DEL-08-04",
    "DEL-08-05", "DEL-08-06", "DEL-08-07",
}

SHORT_FORM_PATTERN = re.compile(r"^DEL-\d{2}-\d{2}$")


def normalize_id(raw_id: str) -> str:
    """Strip descriptive suffix from long-form IDs."""
    if not raw_id:
        return raw_id
    match = re.match(r"^(DEL-\d{2}-\d{2})(?:_.*)?$", raw_id.strip())
    return match.group(1) if match else raw_id.strip()


def parse_csv(csv_path: str) -> tuple:
    """Parse Dependencies.csv and return (headers, rows)."""
    with open(csv_path, "r", newline="", encoding="utf-8") as f:
        reader = csv.DictReader(f)
        headers = reader.fieldnames or []
        rows = list(reader)
    return headers, rows


def check_schema(headers: list) -> dict:
    """Check 1: Schema compliance."""
    missing = [c for c in EXPECTED_COLUMNS_V31 if c not in headers]
    extra = [c for c in headers if c not in EXPECTED_COLUMNS_V31]
    valid = len(missing) == 0
    return {
        "verdict": "PASS" if valid else "BLOCKER",
        "missing_columns": missing,
        "extra_columns": extra,
        "column_count": len(headers),
        "expected_count": len(EXPECTED_COLUMNS_V31),
    }


def filter_edges(rows: list) -> list:
    """Filter rows to qualifying deliverable-to-deliverable edges."""
    edges = []
    for row in rows:
        if FILTER_ACTIVE_ONLY and row.get("Status", "") != "ACTIVE":
            continue
        if row.get("DependencyClass", "") != EDGE_FILTER_CLASS:
            continue
        if row.get("TargetType", "") != EDGE_FILTER_TARGET_TYPE:
            continue
        from_id = normalize_id(row.get("FromDeliverableID", "")) if NORMALIZE_IDS else row.get("FromDeliverableID", "")
        to_id = normalize_id(row.get("TargetDeliverableID", "")) if NORMALIZE_IDS else row.get("TargetDeliverableID", "")
        if from_id and to_id:
            edges.append({
                "dependency_id": row.get("DependencyID", ""),
                "from": from_id,
                "to": to_id,
                "direction": row.get("Direction", ""),
                "type": row.get("DependencyType", ""),
            })
    return edges


def check_orphans(edges: list) -> dict:
    """Check 2: Orphan dependencies."""
    orphans = []
    for e in edges:
        if e["to"] not in VALID_DELIVERABLE_IDS:
            orphans.append(e)
    return {
        "verdict": "PASS" if len(orphans) == 0 else "WARNING",
        "orphan_count": len(orphans),
        "orphans": orphans,
    }


def check_cycles(edges: list) -> dict:
    """Check 3: Circular dependencies (Tarjan SCC on single-source scope)."""
    # Build adjacency list
    graph = defaultdict(set)
    nodes = set()
    for e in edges:
        graph[e["from"]].add(e["to"])
        nodes.add(e["from"])
        nodes.add(e["to"])

    # Tarjan's algorithm
    index_counter = [0]
    stack = []
    lowlink = {}
    index = {}
    on_stack = {}
    sccs = []

    def strongconnect(v):
        index[v] = index_counter[0]
        lowlink[v] = index_counter[0]
        index_counter[0] += 1
        stack.append(v)
        on_stack[v] = True

        for w in graph.get(v, []):
            if w not in index:
                strongconnect(w)
                lowlink[v] = min(lowlink[v], lowlink[w])
            elif on_stack.get(w, False):
                lowlink[v] = min(lowlink[v], index[w])

        if lowlink[v] == index[v]:
            scc = []
            while True:
                w = stack.pop()
                on_stack[w] = False
                scc.append(w)
                if w == v:
                    break
            if len(scc) > 1:
                sccs.append(scc)

    for node in nodes:
        if node not in index:
            strongconnect(node)

    return {
        "verdict": "PASS" if len(sccs) == 0 else "BLOCKER",
        "scc_count": len(sccs),
        "sccs": sccs[:MAX_CYCLES],
    }


def check_anchors(rows: list) -> dict:
    """Check 4: Anchor coverage."""
    anchors = [
        r for r in rows
        if r.get("DependencyClass") == "ANCHOR"
        and r.get("AnchorType") == "IMPLEMENTS_NODE"
        and r.get("Status") == "ACTIVE"
    ]
    return {
        "verdict": "PASS" if len(anchors) > 0 else "WARNING",
        "implements_node_count": len(anchors),
    }


def check_misplaced_fields(rows: list) -> dict:
    """Check 5: Misplaced fields."""
    misplaced = []
    for row in rows:
        target_type = row.get("TargetType", "")
        target_del_id = row.get("TargetDeliverableID", "").strip()
        if target_type != "DELIVERABLE" and target_del_id:
            misplaced.append({
                "dependency_id": row.get("DependencyID", ""),
                "target_type": target_type,
                "target_deliverable_id": target_del_id,
            })
    return {
        "verdict": "PASS" if len(misplaced) == 0 else "WARNING",
        "misplaced_count": len(misplaced),
        "misplaced": misplaced,
    }


def check_id_format(rows: list) -> dict:
    """Check 6: ID format consistency."""
    all_ids = []
    for row in rows:
        fid = row.get("FromDeliverableID", "").strip()
        tid = row.get("TargetDeliverableID", "").strip()
        if fid:
            all_ids.append(fid)
        if tid:
            all_ids.append(tid)
    long_form = [i for i in all_ids if not SHORT_FORM_PATTERN.match(i)]
    rate = len(long_form) / len(all_ids) if all_ids else 0.0
    return {
        "verdict": "PASS" if len(long_form) == 0 else "WARNING",
        "long_form_count": len(long_form),
        "short_form_count": len(all_ids) - len(long_form),
        "normalization_rate": rate,
    }


def check_isolated(edges: list) -> dict:
    """Check 7: Isolated deliverables."""
    connected = set()
    for e in edges:
        connected.add(e["from"])
        connected.add(e["to"])
    is_isolated = SCOPE_DELIVERABLE not in connected
    return {
        "verdict": "PASS" if not is_isolated else "WARNING",
        "isolated": is_isolated,
        "edge_count": len(edges),
    }


def check_hubs(edges: list) -> dict:
    """Check 8: Hub analysis."""
    degree = defaultdict(int)
    for e in edges:
        degree[e["from"]] += 1
        degree[e["to"]] += 1
    hubs = {k: v for k, v in degree.items() if v >= HUB_THRESHOLD}
    max_deg = max(degree.values()) if degree else 0
    return {
        "verdict": "PASS" if len(hubs) == 0 else "WARNING",
        "hub_count": len(hubs),
        "max_degree": max_deg,
        "hubs": hubs,
    }


def check_bidirectional(edges: list) -> dict:
    """Check 9: Bidirectional pairs."""
    edge_set = set()
    for e in edges:
        edge_set.add((e["from"], e["to"]))
    pairs = []
    for a, b in edge_set:
        if (b, a) in edge_set and a < b:
            pairs.append((a, b))
    return {
        "verdict": "PASS" if len(pairs) == 0 else "INFO",
        "pair_count": len(pairs),
        "pairs": pairs,
    }


def main():
    execution_root = DEFAULT_EXECUTION_ROOT
    if len(sys.argv) > 2 and sys.argv[1] == "--execution-root":
        execution_root = sys.argv[2]

    csv_path = os.path.join(execution_root, "..",  DELIVERABLE_PATH, "Dependencies.csv")
    # Normalize to handle the default case
    csv_path = os.path.join(DELIVERABLE_PATH, "Dependencies.csv")

    if not os.path.isfile(csv_path):
        print(f"ERROR: Dependencies.csv not found at {csv_path}")
        sys.exit(1)

    print(f"Analyzing: {csv_path}")
    print(f"Scope: {SCOPE_DELIVERABLE}")
    print()

    headers, rows = parse_csv(csv_path)

    # Check 1: Schema
    schema_result = check_schema(headers)
    print(f"Check 1 (Schema compliance): {schema_result['verdict']}")

    # Filter edges
    edges = filter_edges(rows)
    print(f"Qualifying edges: {len(edges)} of {len(rows)} rows")
    print()

    # Check 2: Orphans
    orphan_result = check_orphans(edges)
    print(f"Check 2 (Orphan dependencies): {orphan_result['verdict']} ({orphan_result['orphan_count']} orphans)")

    # Check 3: Cycles
    cycle_result = check_cycles(edges)
    print(f"Check 3 (Circular dependencies): {cycle_result['verdict']} ({cycle_result['scc_count']} SCCs)")

    # Check 4: Anchors
    anchor_result = check_anchors(rows)
    print(f"Check 4 (Anchor coverage): {anchor_result['verdict']} ({anchor_result['implements_node_count']} IMPLEMENTS_NODE)")

    # Check 5: Misplaced fields
    misplaced_result = check_misplaced_fields(rows)
    print(f"Check 5 (Misplaced fields): {misplaced_result['verdict']} ({misplaced_result['misplaced_count']} misplaced)")

    # Check 6: ID format
    id_result = check_id_format(rows)
    print(f"Check 6 (ID format consistency): {id_result['verdict']} ({id_result['long_form_count']} long-form)")

    # Check 7: Isolated
    isolated_result = check_isolated(edges)
    print(f"Check 7 (Isolated deliverables): {isolated_result['verdict']} (isolated={isolated_result['isolated']})")

    # Check 8: Hubs
    hub_result = check_hubs(edges)
    print(f"Check 8 (Hub analysis): {hub_result['verdict']} (max_degree={hub_result['max_degree']})")

    # Check 9: Bidirectional
    bidir_result = check_bidirectional(edges)
    print(f"Check 9 (Bidirectional pairs): {bidir_result['verdict']} ({bidir_result['pair_count']} pairs)")

    print()
    verdicts = [
        schema_result["verdict"],
        orphan_result["verdict"],
        cycle_result["verdict"],
        anchor_result["verdict"],
        misplaced_result["verdict"],
        id_result["verdict"],
        isolated_result["verdict"],
        hub_result["verdict"],
        bidir_result["verdict"],
    ]
    if "BLOCKER" in verdicts:
        overall = "BLOCKER"
    elif "WARNING" in verdicts:
        overall = "WARNINGS"
    else:
        overall = "PASS"

    print(f"Overall closure status: {overall}")

    # Output JSON summary
    summary = {
        "run_label": "DEL-08-02",
        "date": "2026-02-21",
        "scope": SCOPE_DELIVERABLE,
        "closure_status": overall,
        "checks": {
            "schema_compliance": schema_result["verdict"],
            "orphan_dependencies": orphan_result["verdict"],
            "circular_dependencies": cycle_result["verdict"],
            "anchor_coverage": anchor_result["verdict"],
            "misplaced_fields": misplaced_result["verdict"],
            "id_format_consistency": id_result["verdict"],
            "isolated_deliverables": isolated_result["verdict"],
            "hub_analysis": hub_result["verdict"],
            "bidirectional_pairs": bidir_result["verdict"],
        },
    }
    print()
    print("JSON summary:")
    print(json.dumps(summary, indent=2))


if __name__ == "__main__":
    main()
